{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**tree traveersal**"
      ],
      "metadata": {
        "id": "WIiyCc9Ry8U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install all the dependencies**"
      ],
      "metadata": {
        "id": "1Pnl218_SpX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install python-pptx\n",
        "!pip install ffmpeg-python\n",
        "!pip install transformers\n",
        "!apt install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi332LQ5y6QC",
        "outputId": "512dc3bc-5a13-4303-fa6c-14cdd3175623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-6x3nb_u1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-6x3nb_u1\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.13.2)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert the files from mkv to mp4 to support whisper api**"
      ],
      "metadata": {
        "id": "1V7Ue8JdSoDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replace the video/audio/pdf/ppt files with your respective paths after uploading ( here its uploaded on colab )**"
      ],
      "metadata": {
        "id": "MAVNFgRiKpb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def convert_mkv_to_mp4(input_path, output_path):\n",
        "    ffmpeg.input(input_path).output(output_path).run(overwrite_output=True)\n",
        "    print(f\"Converted {input_path} to {output_path}\")\n",
        "\n",
        "video_mkv = \"/content/9a_2020-09-16 09-46-13_TreeTravCon.mkv\"\n",
        "video_mp4 = \"/content/converted_video.mp4\"\n",
        "convert_mkv_to_mp4(video_mkv, video_mp4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FiNCozw1PsP",
        "outputId": "9a22fb82-5acb-44c7-969a-d45e7e3f07d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted /content/9a_2020-09-16 09-46-13_TreeTravCon.mkv to /content/converted_video.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the audio files **"
      ],
      "metadata": {
        "id": "MjKy3bRnTBq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio(video_path, audio_path=\"/content/audio.wav\"):\n",
        "    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    print(\"Audio extracted:\", audio_path)\n",
        "    return audio_path\n",
        "\n",
        "audio_file = extract_audio(video_mp4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu1xFRqQ1__t",
        "outputId": "1ddbe0cd-98da-4ab3-c5df-6725574ac8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio extracted: /content/audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code converts an MKV file to MP4, extracts its audio as a WAV file, and then transcribes the audio using OpenAI’s Whisper model. It ensures both video and audio formats are compatible for accurate transcription."
      ],
      "metadata": {
        "id": "1JPrwK6-TG1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def convert_and_extract_audio(mkv_path):\n",
        "    mp4_path = mkv_path.replace(\".mkv\", \".mp4\")\n",
        "    audio_path = \"/content/audio.wav\"\n",
        "\n",
        "    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)\n",
        "    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "\n",
        "    return mp4_path, audio_path\n",
        "\n",
        "video_path = \"/content/9a_2020-09-16 09-46-13_TreeTravCon.mkv\"\n",
        "converted_mp4, audio_file = convert_and_extract_audio(video_path)\n"
      ],
      "metadata": {
        "id": "QTdMr1FU31ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")  # or \"large\" for even better quality\n",
        "result = model.transcribe(audio_file)\n",
        "full_transcript = result[\"text\"]\n"
      ],
      "metadata": {
        "id": "MbnniUVE3-V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code extracts titles, content, and speaker notes from each slide in a PowerPoint (.pptx) file. It organizes the extracted data into a structured list of dictionaries for further processing."
      ],
      "metadata": {
        "id": "I0cHBSE8TN8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "\n",
        "def extract_ppt_content(ppt_path):\n",
        "    prs = Presentation(ppt_path)\n",
        "    slides = []\n",
        "\n",
        "    for i, slide in enumerate(prs.slides):\n",
        "        slide_dict = {'title': '', 'content': [], 'notes': ''}\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                text = shape.text.strip()\n",
        "                if shape == slide.shapes[0]:\n",
        "                    slide_dict['title'] = text\n",
        "                else:\n",
        "                    slide_dict['content'].append(text)\n",
        "\n",
        "        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "            slide_dict['notes'] = slide.notes_slide.notes_text_frame.text.strip()\n",
        "\n",
        "        slides.append(slide_dict)\n",
        "    return slides\n",
        "\n",
        "ppt_path = \"/content/class9_Unit3_Trees_naryTraversal.pptx\"\n",
        "slide_data = extract_ppt_content(ppt_path)\n"
      ],
      "metadata": {
        "id": "28I2VOT05Lt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdr2mTtM5Xps",
        "outputId": "9bf414b8-a5ad-41c2-d45d-90c90c812618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fpdf\n",
            "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fpdf\n",
            "  Building wheel for fpdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40704 sha256=af737b5695bd079972fce8b8836cdfdd604f273566e480bc9cf38132c4817e06\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/66/bbda9866da446a72e206d6484cd97381cbc7859a7068541c36\n",
            "Successfully built fpdf\n",
            "Installing collected packages: fpdf\n",
            "Successfully installed fpdf-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code compiles the transcribed audio and extracted slide content into a well-formatted PDF titled Lecture Notes. It organizes each slide's title, content, and notes using the fpdf library and saves the final output.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8M7h0eudTXGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1, align=\"L\")\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "# Add full transcript\n",
        "pdf.chapter_title(\"Full Transcript\")\n",
        "pdf.chapter_body(full_transcript)\n",
        "\n",
        "# Add slide contents\n",
        "for i, slide in enumerate(slide_data):\n",
        "    pdf.chapter_title(f\"Slide {i+1}: {slide['title']}\")\n",
        "    for point in slide['content']:\n",
        "        pdf.chapter_body(f\"- {point}\")\n",
        "    if slide['notes']:\n",
        "        pdf.chapter_body(f\"Notes: {slide['notes']}\")\n",
        "    pdf.ln()\n",
        "\n",
        "output_pdf_path = \"/content/Combined_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf_path)\n",
        "print(f\"✅ PDF saved: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKJXOP_v5O44",
        "outputId": "1ae5e0a6-aa51-42f5-ecd7-e594f25167b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PDF saved: /content/Combined_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_kTMpkiT5biN",
        "outputId": "8e8b2645-8b36-4cac-cef2-064408ea8cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de0f41e6-f4c3-48d1-8352-dadeb2038223\", \"Combined_Lecture_Notes.pdf\", 13828)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The same steps are repeated for each of the other subtopics **"
      ],
      "metadata": {
        "id": "bxbkUnjcTnQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agentic**"
      ],
      "metadata": {
        "id": "3apAkwHD7RSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install ffmpeg-python\n",
        "!pip install PyMuPDF fpdf\n",
        "!apt install ffmpeg -y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1qNWhFJ6cAt",
        "outputId": "d3557e9a-877e-425c-f7d9-285dc19ae2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-7krrpznd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-7krrpznd\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.5\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def extract_audio(video_path, audio_path=\"/content/audio_agentic.wav\"):\n",
        "    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    return audio_path\n",
        "\n",
        "video_path = \"/content/19853_shylaja.sharath_31_20250401121200417_Video_ENC.mp4\"\n",
        "audio_path = extract_audio(video_path)\n"
      ],
      "metadata": {
        "id": "tPCAtaYr8BSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")  # Or \"large\" for better quality\n",
        "result = model.transcribe(audio_file)\n",
        "full_transcript = result[\"text\"]\n"
      ],
      "metadata": {
        "id": "-JF4ZhV48eA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += page.get_text()\n",
        "    return full_text.strip()\n",
        "\n",
        "slide_text_1 = extract_text_from_pdf(\"/content/Agentic Workflow.pdf\")\n",
        "slide_text_2 = extract_text_from_pdf(\"/content/AutoGen, CrewAI.pdf\")\n",
        "\n",
        "combined_slide_text = f\"{slide_text_1}\\n\\n---\\n\\n{slide_text_2}\"\n"
      ],
      "metadata": {
        "id": "hv73HO-r9Gr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Define clean_text and generate final PDF\n",
        "from fpdf import FPDF\n",
        "\n",
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")  # removes any non-ascii character\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')         # en-dash\n",
        "        .replace('\\u2014', '-')         # em-dash\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Agentic Workflow - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.chapter_title(\"Video Transcript\")\n",
        "pdf.chapter_body(clean_text(full_transcript))\n",
        "\n",
        "pdf.chapter_title(\"Slide Content - Agentic Workflow & CrewAI\")\n",
        "pdf.chapter_body(clean_text(combined_slide_text))\n",
        "\n",
        "output_pdf_path = \"/content/Agentic_Complete_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf_path)\n",
        "print(f\"✅ Full Lecture Notes PDF saved to: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwCO4J1V9gbV",
        "outputId": "c97ee3ad-33fa-4062-fca4-0d47f9dfba10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Full Lecture Notes PDF saved to: /content/Agentic_Complete_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Download the final output\n",
        "from google.colab import files\n",
        "files.download(output_pdf_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IsiWeSWf9lLG",
        "outputId": "83544835-e6f7-4609-cfac-1239d1879639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_246ebdb6-8b17-4149-8235-4ae41588b112\", \"Agentic_Complete_Lecture_Notes.pdf\", 23659)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BST**"
      ],
      "metadata": {
        "id": "KfekIjgd-jb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-pptx fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1hijFEi-rH9",
        "outputId": "f6903342-587d-4e42-f7b5-ff1232e2178d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "\n",
        "def extract_pptx_text(path):\n",
        "    prs = Presentation(path)\n",
        "    content = \"\"\n",
        "\n",
        "    for i, slide in enumerate(prs.slides):\n",
        "        slide_title = \"\"\n",
        "        bullet_points = []\n",
        "        notes = \"\"\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                text = shape.text.strip()\n",
        "                if shape == slide.shapes[0] and not slide_title:\n",
        "                    slide_title = text\n",
        "                else:\n",
        "                    bullet_points.append(text)\n",
        "\n",
        "        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "            notes = slide.notes_slide.notes_text_frame.text.strip()\n",
        "\n",
        "        content += f\"\\n\\nSlide {i+1}: {slide_title}\\n\"\n",
        "        for bullet in bullet_points:\n",
        "            content += f\"- {bullet}\\n\"\n",
        "        if notes:\n",
        "            content += f\"Notes: {notes}\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "# Paths to the 3 files\n",
        "ppt1 = \"/content/Class2_Unit3_Tree_BST_DynamicInsert.pptx\"\n",
        "ppt2 = \"/content/Class3_Unit3_Trees_BSTDeletion.pptx\"\n",
        "ppt3 = \"/content/Class4_Unit3_Trees_BST_ArrayInsert.pptx\"\n",
        "\n",
        "# Combine all content\n",
        "combined_bst_text = (\n",
        "    extract_pptx_text(ppt1)\n",
        "    + \"\\n\\n\" + extract_pptx_text(ppt2)\n",
        "    + \"\\n\\n\" + extract_pptx_text(ppt3)\n",
        ")\n"
      ],
      "metadata": {
        "id": "mRzKnIks_hD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')\n",
        "        .replace('\\u2014', '-')\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "PlisLwcl_viy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Binary Search Tree (BST) - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "pdf.chapter_title(\"Combined Slide Transcription - BST Lectures\")\n",
        "pdf.chapter_body(clean_text(combined_bst_text))\n",
        "\n",
        "output_pdf_path = \"/content/BST_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf_path)\n",
        "print(f\"✅ PDF created: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owbClWHZ_0-z",
        "outputId": "821b6583-88ae-48a7-99e8-15384a069ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PDF created: /content/BST_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h-xb96Er_4XZ",
        "outputId": "8f768d56-9c91-4a19-d0c4-c45bbe421a06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_31433fdf-d2b1-4f6b-873e-524bca8b0559\", \"BST_Lecture_Notes.pdf\", 7909)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TBT**"
      ],
      "metadata": {
        "id": "SCXIM42BAMwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def convert_and_extract_audio(mkv_path, out_prefix):\n",
        "    mp4_path = mkv_path.replace(\".mkv\", f\"_{out_prefix}.mp4\")\n",
        "    audio_path = f\"/content/audio_{out_prefix}.wav\"\n",
        "\n",
        "    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)\n",
        "    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    return audio_path\n",
        "\n",
        "# Convert and extract from both videos\n",
        "audio1 = convert_and_extract_audio(\"/content/6a_2020-09-22 09-49-32_TBTCon.mkv\", \"part1\")\n",
        "audio2 = convert_and_extract_audio(\"/content/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_19~8.mkv\", \"part2\")\n"
      ],
      "metadata": {
        "id": "rGp_Tj7_AXb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large\")  # or \"large\" for even higher accuracy\n",
        "\n",
        "transcript1 = model.transcribe(audio1)[\"text\"]\n",
        "transcript2 = model.transcribe(audio2)[\"text\"]\n",
        "\n",
        "full_video_transcript = transcript1 + \"\\n\\n---\\n\\n\" + transcript2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk7dYiJgEwIc",
        "outputId": "3e3aeeb2-705f-49c8-c7ce-b8f4fa1c2c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:06<00:00, 46.1MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "\n",
        "def extract_pptx_text(path):\n",
        "    prs = Presentation(path)\n",
        "    content = \"\"\n",
        "\n",
        "    for i, slide in enumerate(prs.slides):\n",
        "        slide_title = \"\"\n",
        "        bullet_points = []\n",
        "        notes = \"\"\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                text = shape.text.strip()\n",
        "                if shape == slide.shapes[0] and not slide_title:\n",
        "                    slide_title = text\n",
        "                else:\n",
        "                    bullet_points.append(text)\n",
        "\n",
        "        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "            notes = slide.notes_slide.notes_text_frame.text.strip()\n",
        "\n",
        "        content += f\"\\n\\nSlide {i+1}: {slide_title}\\n\"\n",
        "        for bullet in bullet_points:\n",
        "            content += f\"- {bullet}\\n\"\n",
        "        if notes:\n",
        "            content += f\"Notes: {notes}\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "ppt_path = \"/content/Class6_Unit3_Trees_ThreadBST.pptx\"\n",
        "slide_text = extract_pptx_text(ppt_path)\n"
      ],
      "metadata": {
        "id": "PMa-5_U2Kimq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')\n",
        "        .replace('\\u2014', '-')\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "-KoVfcHSKo3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Threaded Binary Tree (TBT) - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.chapter_title(\"Video Transcript (Part 1 + Part 2)\")\n",
        "pdf.chapter_body(clean_text(full_video_transcript))\n",
        "\n",
        "pdf.chapter_title(\"Slide Content from PPT\")\n",
        "pdf.chapter_body(clean_text(slide_text))\n",
        "\n",
        "output_pdf = \"/content/TBT_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf)\n",
        "print(f\"✅ Final TBT Lecture PDF saved: {output_pdf}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwo0Q4uvKr_n",
        "outputId": "1191f22b-5fe8-4717-dcc5-26ff9c272f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final TBT Lecture PDF saved: /content/TBT_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ebmOH0GmKvEA",
        "outputId": "205fe23e-ce85-45cd-8d63-3d3216754e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_61f411eb-6729-44de-8788-0329c9c5c1a4\", \"TBT_Lecture_Notes.pdf\", 33924)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**heap**"
      ],
      "metadata": {
        "id": "2ljOEYfsLhtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def convert_and_extract_audio(mkv_path, out_prefix):\n",
        "    mp4_path = mkv_path.replace(\".mkv\", f\"_{out_prefix}.mp4\")\n",
        "    audio_path = f\"/content/audio_{out_prefix}.wav\"\n",
        "\n",
        "    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)\n",
        "    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    return audio_path\n",
        "\n",
        "audio1 = convert_and_extract_audio(\"/content/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_12~1.mkv\", \"heap_part1\")\n",
        "audio2 = convert_and_extract_audio(\"/content/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50.mkv\", \"heap_part2\")\n"
      ],
      "metadata": {
        "id": "bP39qgK3Ljcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")  # Or \"large\" for best results\n",
        "\n",
        "transcript1 = model.transcribe(audio1)[\"text\"]\n",
        "transcript2 = model.transcribe(audio2)[\"text\"]\n",
        "\n",
        "heap_full_transcript = transcript1 + \"\\n\\n---\\n\\n\" + transcript2\n"
      ],
      "metadata": {
        "id": "FMd121zuRGVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "\n",
        "def extract_pptx_text(path):\n",
        "    prs = Presentation(path)\n",
        "    content = \"\"\n",
        "\n",
        "    for i, slide in enumerate(prs.slides):\n",
        "        slide_title = \"\"\n",
        "        bullet_points = []\n",
        "        notes = \"\"\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                text = shape.text.strip()\n",
        "                if shape == slide.shapes[0] and not slide_title:\n",
        "                    slide_title = text\n",
        "                else:\n",
        "                    bullet_points.append(text)\n",
        "\n",
        "        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "            notes = slide.notes_slide.notes_text_frame.text.strip()\n",
        "\n",
        "        content += f\"\\n\\nSlide {i+1}: {slide_title}\\n\"\n",
        "        for bullet in bullet_points:\n",
        "            content += f\"- {bullet}\\n\"\n",
        "        if notes:\n",
        "            content += f\"Notes: {notes}\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "ppt_path = \"/content/Class8_Unit3_Trees_Heap.pptx\"\n",
        "heap_slide_text = extract_pptx_text(ppt_path)\n"
      ],
      "metadata": {
        "id": "oPlypMuETbzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')\n",
        "        .replace('\\u2014', '-')\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "6iQzEft0V7Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Heap - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.chapter_title(\"Video Transcript (Both Parts)\")\n",
        "pdf.chapter_body(clean_text(heap_full_transcript))\n",
        "\n",
        "pdf.chapter_title(\"Slide Content - Heap PPT\")\n",
        "pdf.chapter_body(clean_text(heap_slide_text))\n",
        "\n",
        "output_pdf_path = \"/content/Heap_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf_path)\n",
        "print(f\"✅ Final Heap Lecture PDF saved: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9atUSTglV-Wq",
        "outputId": "67838535-5960-4c3c-e245-28209925bd46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Heap Lecture PDF saved: /content/Heap_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf_path)\n"
      ],
      "metadata": {
        "id": "mmDN1r3DWBHi",
        "outputId": "9777796b-08b5-4783-cd2e-5ae0aeece13b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5de0f05f-a583-4a06-8217-4920f704206a\", \"Heap_Lecture_Notes.pdf\", 46469)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**exp_tree**"
      ],
      "metadata": {
        "id": "ecfuuzCsXqCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def convert_and_extract_audio(mkv_path, out_prefix):\n",
        "    mp4_path = mkv_path.replace(\".mkv\", f\"_{out_prefix}.mp4\")\n",
        "    audio_path = f\"/content/audio_{out_prefix}.wav\"\n",
        "\n",
        "    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)\n",
        "    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    return audio_path\n",
        "\n",
        "audio1 = convert_and_extract_audio(\"/content/7a_2020-09-24 09-28-52_ExprTreeCon.mkv\", \"expn1\")\n",
        "audio2 = convert_and_extract_audio(\"/content/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52.mkv\", \"expn2\")\n"
      ],
      "metadata": {
        "id": "8cIsfnLTXsud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large\")\n",
        "transcript1 = model.transcribe(audio1)[\"text\"]\n",
        "transcript2 = model.transcribe(audio2)[\"text\"]\n",
        "\n",
        "full_expn_transcript = transcript1 + \"\\n\\n---\\n\\n\" + transcript2\n"
      ],
      "metadata": {
        "id": "4DV0EzywZhkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "\n",
        "def extract_pptx_text(path):\n",
        "    prs = Presentation(path)\n",
        "    content = \"\"\n",
        "\n",
        "    for i, slide in enumerate(prs.slides):\n",
        "        slide_title = \"\"\n",
        "        bullet_points = []\n",
        "        notes = \"\"\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                text = shape.text.strip()\n",
        "                if shape == slide.shapes[0] and not slide_title:\n",
        "                    slide_title = text\n",
        "                else:\n",
        "                    bullet_points.append(text)\n",
        "\n",
        "        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "            notes = slide.notes_slide.notes_text_frame.text.strip()\n",
        "\n",
        "        content += f\"\\n\\nSlide {i+1}: {slide_title}\\n\"\n",
        "        for bullet in bullet_points:\n",
        "            content += f\"- {bullet}\\n\"\n",
        "        if notes:\n",
        "            content += f\"Notes: {notes}\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "expn_slide_text = extract_pptx_text(\"/content/Class7_Unit3_Trees_ExprTree.pptx\")\n"
      ],
      "metadata": {
        "id": "ZyC4ctXdb7PP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')\n",
        "        .replace('\\u2014', '-')\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Hcj3w2q0b9li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Expression Tree - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.chapter_title(\"Video Transcript (Part 1 + Part 2)\")\n",
        "pdf.chapter_body(clean_text(full_expn_transcript))\n",
        "\n",
        "pdf.chapter_title(\"Slide Content - Expression Tree PPT\")\n",
        "pdf.chapter_body(clean_text(expn_slide_text))\n",
        "\n",
        "output_pdf = \"/content/ExpressionTree_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf)\n",
        "print(f\"✅ Final Expression Tree Lecture PDF saved: {output_pdf}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTaLfAXCcACO",
        "outputId": "ac9c589d-8099-4f02-baa2-062b67a1bcbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Expression Tree Lecture PDF saved: /content/ExpressionTree_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RVg9wkxZcChI",
        "outputId": "abe91549-003a-497b-bc52-efbbd4c1f7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1fff439c-75b3-4992-9fdd-ffcba9aad91a\", \"ExpressionTree_Lecture_Notes.pdf\", 20398)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stable Diffusion**"
      ],
      "metadata": {
        "id": "M5cmu6cJcu3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def extract_audio(video_path, out_name):\n",
        "    audio_path = f\"/content/audio_{out_name}.wav\"\n",
        "    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    return audio_path\n",
        "\n",
        "audio1 = extract_audio(\"/content/19853_shylaja.sharath_31_20250327084200249_Video_ENC.mp4\", \"stable1\")\n",
        "audio2 = extract_audio(\"/content/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1).mp4\", \"stable2\")\n"
      ],
      "metadata": {
        "id": "aLyNb9m6c8it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large\")  # or \"large\"\n",
        "\n",
        "transcript1 = model.transcribe(audio1)[\"text\"]\n",
        "transcript2 = model.transcribe(audio2)[\"text\"]\n",
        "\n",
        "full_stable_video_transcript = transcript1 + \"\\n\\n---\\n\\n\" + transcript2\n"
      ],
      "metadata": {
        "id": "34kObMD0eAlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text.strip()\n",
        "\n",
        "slide_text = extract_text_from_pdf(\"/content/Stable Diffusion.pdf\")\n"
      ],
      "metadata": {
        "id": "caN2MD2Wk1i7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')\n",
        "        .replace('\\u2014', '-')\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "lIkj83gWk4fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"Stable Diffusion - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.chapter_title(\"Video Transcript (Both Videos)\")\n",
        "pdf.chapter_body(clean_text(full_stable_video_transcript))\n",
        "\n",
        "pdf.chapter_title(\"Slide Content - Stable Diffusion PDF\")\n",
        "pdf.chapter_body(clean_text(slide_text))\n",
        "\n",
        "output_pdf = \"/content/StableDiffusion_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf)\n",
        "print(f\"✅ Final Stable Diffusion Lecture PDF saved: {output_pdf}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_aFMO71k6_x",
        "outputId": "a93a9af0-4567-450c-d6bf-39694c3c4dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Stable Diffusion Lecture PDF saved: /content/StableDiffusion_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PgKtR36Ok9RI",
        "outputId": "b5b2768f-620d-4ab3-9c9b-01a769e95812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e25a94ee-b3dd-42b1-9dfb-68af29b4b4eb\", \"StableDiffusion_Lecture_Notes.pdf\", 47787)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Tree Traversal**"
      ],
      "metadata": {
        "id": "WG7WuQVLluos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "def convert_and_extract_audio(mkv_path, out_prefix):\n",
        "    mp4_path = mkv_path.replace(\".mkv\", f\"_{out_prefix}.mp4\")\n",
        "    audio_path = f\"/content/audio_{out_prefix}.wav\"\n",
        "\n",
        "    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)\n",
        "    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)\n",
        "    return audio_path\n",
        "\n",
        "audio_path = convert_and_extract_audio(\"/content/5a_2020-09-15 09-04-51_BinTraversal.mkv\", \"bst_traversal\")\n"
      ],
      "metadata": {
        "id": "a0Q3GTKAmPRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"medium\")  # or \"large\"\n",
        "transcript = model.transcribe(audio_path)[\"text\"]\n"
      ],
      "metadata": {
        "id": "4lzR9NSOswjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "\n",
        "def extract_pptx_text(path):\n",
        "    prs = Presentation(path)\n",
        "    content = \"\"\n",
        "\n",
        "    for i, slide in enumerate(prs.slides):\n",
        "        slide_title = \"\"\n",
        "        bullet_points = []\n",
        "        notes = \"\"\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                text = shape.text.strip()\n",
        "                if shape == slide.shapes[0] and not slide_title:\n",
        "                    slide_title = text\n",
        "                else:\n",
        "                    bullet_points.append(text)\n",
        "\n",
        "        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:\n",
        "            notes = slide.notes_slide.notes_text_frame.text.strip()\n",
        "\n",
        "        content += f\"\\n\\nSlide {i+1}: {slide_title}\\n\"\n",
        "        for bullet in bullet_points:\n",
        "            content += f\"- {bullet}\\n\"\n",
        "        if notes:\n",
        "            content += f\"Notes: {notes}\\n\"\n",
        "\n",
        "    return content\n",
        "\n",
        "ppt_text = extract_pptx_text(\"/content/Class5_Unit3_BST_Traversal.pptx\")\n"
      ],
      "metadata": {
        "id": "VylzGeZDt8ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return (\n",
        "        text.encode(\"ascii\", \"ignore\")\n",
        "        .decode(\"ascii\")\n",
        "        .replace('\\u2013', '-')\n",
        "        .replace('\\u2014', '-')\n",
        "        .replace('\\u2018', \"'\")\n",
        "        .replace('\\u2019', \"'\")\n",
        "        .replace('\\u201c', '\"')\n",
        "        .replace('\\u201d', '\"')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "FSYnAhHMt-72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font(\"Arial\", \"B\", 14)\n",
        "        self.cell(0, 10, \"BST Traversal - Lecture Notes\", ln=1, align=\"C\")\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font(\"Arial\", \"B\", 12)\n",
        "        self.cell(0, 10, title, ln=1)\n",
        "        self.ln(2)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font(\"Arial\", \"\", 11)\n",
        "        self.multi_cell(0, 8, body)\n",
        "        self.ln()\n",
        "\n",
        "pdf = PDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.chapter_title(\"Video Transcript\")\n",
        "pdf.chapter_body(clean_text(transcript))\n",
        "\n",
        "pdf.chapter_title(\"Slide Content - BST Traversal PPT\")\n",
        "pdf.chapter_body(clean_text(ppt_text))\n",
        "\n",
        "output_pdf_path = \"/content/BST_Traversal_Lecture_Notes.pdf\"\n",
        "pdf.output(output_pdf_path)\n",
        "print(f\"✅ Final BST Traversal Lecture PDF saved: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "id": "CSXSMAeeuBGx",
        "outputId": "e9985174-541f-4c35-d69f-81c005f95846",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final BST Traversal Lecture PDF saved: /content/BST_Traversal_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(output_pdf_path)\n"
      ],
      "metadata": {
        "id": "x8lWGuK2uEzK",
        "outputId": "81dbed59-f223-476a-f33d-d24b198cc3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4689d9ba-34dc-4344-8649-d022ded4e24a\", \"BST_Traversal_Lecture_Notes.pdf\", 46393)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# text summarization"
      ],
      "metadata": {
        "id": "5v-tJZpWR6wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fitz\n",
        "import requests\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"my_key\"\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def generate_notes_with_groq(transcript_text):\n",
        "    prompt = f\"\"\"\n",
        "You are an educational assistant. Your task is to generate detailed, well-structured lecture notes\n",
        "by combining the transcript and slides content below. Do NOT include any introduction, explanation, or instructions in your output.\n",
        "Follow these rules:\n",
        "1. Use headings and subheadings.\n",
        "2. Highlight key concepts and definitions.\n",
        "3. Summarize lengthy explanations concisely.\n",
        "4. Maintain logical flow.\n",
        "5. Add bullet points for clarity.\n",
        "---Transcript---\n",
        "{transcript_text}\n",
        "\n",
        "Return only the structured notes.\n",
        "\"\"\"\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "        headers={\"Authorization\": f\"Bearer {GROQ_API_KEY}\"},\n",
        "        json={\n",
        "            \"model\": \"qwen-qwq-32b\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"temperature\": 0.3,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    response_json = response.json()\n",
        "    if \"choices\" not in response_json:\n",
        "        print(\"Error response from Groq:\", response_json)\n",
        "        return \"Groq API error: could not generate notes.\"\n",
        "\n",
        "    return response_json[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "transcript = extract_text_from_pdf(\"/content/ExpressionTree_Combined.pdf\")\n",
        "lecture_notes = generate_notes_with_groq(transcript)\n",
        "\n",
        "with open(\"expressiontree_notes.md\", \"w\") as f:\n",
        "    f.write(lecture_notes)\n",
        "\n",
        "print(\"Lecture notes generated and saved.\")\n"
      ],
      "metadata": {
        "id": "IQKF3-xXrhDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image extraction"
      ],
      "metadata": {
        "id": "e8vhwUtdQlB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import shutil\n",
        "import platform\n",
        "\n",
        "# --- STEP 1: Convert PPTX to PDF ---\n",
        "def convert_pptx_to_pdf_windows(input_path, output_path):\n",
        "    import comtypes.client\n",
        "    powerpoint = comtypes.client.CreateObject(\"PowerPoint.Application\")\n",
        "    powerpoint.Visible = 1\n",
        "    deck = powerpoint.Presentations.Open(input_path)\n",
        "    deck.SaveAs(output_path, 32)  # 32 = PDF\n",
        "    deck.Close()\n",
        "    powerpoint.Quit()\n",
        "\n",
        "def convert_pptx_to_pdf_linux(input_path, output_path):\n",
        "    os.system(f'unoconv -f pdf -o \"{output_path}\" \"{input_path}\"')\n",
        "\n",
        "def convert_all_pptx_to_pdf(root_dir):\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for file in filenames:\n",
        "            if file.endswith(\".pptx\"):\n",
        "                pptx_path = os.path.join(dirpath, file)\n",
        "                pdf_name = file.replace(\".pptx\", \".pdf\")\n",
        "                pdf_path = os.path.join(dirpath, pdf_name)\n",
        "                try:\n",
        "                    if platform.system() == \"Windows\":\n",
        "                        convert_pptx_to_pdf_windows(pptx_path, pdf_path)\n",
        "                    else:\n",
        "                        convert_pptx_to_pdf_linux(pptx_path, pdf_path)\n",
        "                    print(f\"[✓] Converted: {pptx_path} -> {pdf_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"[✗] Failed to convert {pptx_path}: {e}\")\n",
        "\n",
        "# --- STEP 2: PDF Image Extraction ---\n",
        "def images_are_similar(img1_bytes, img2_bytes, threshold=0.96):\n",
        "    img1 = Image.open(io.BytesIO(img1_bytes)).convert(\"L\")\n",
        "    img2 = Image.open(io.BytesIO(img2_bytes)).convert(\"L\")\n",
        "    if img1.size != img2.size:\n",
        "        return False\n",
        "    score, _ = ssim(np.array(img1), np.array(img2), full=True)\n",
        "    return score >= threshold\n",
        "\n",
        "def extract_unique_images_from_pdf(pdf_path, output_dir):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    pdf = fitz.open(pdf_path)\n",
        "    saved_images = []\n",
        "    skipped_logos = []\n",
        "    saved_paths = []\n",
        "\n",
        "    for page_num in range(len(pdf)):\n",
        "        page = pdf[page_num]\n",
        "        images = page.get_images(full=True)\n",
        "        for i, img in enumerate(images):\n",
        "            xref = img[0]\n",
        "            base_image = pdf.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image_ext = base_image[\"ext\"]\n",
        "\n",
        "            is_logo = False\n",
        "            for logo_img in skipped_logos:\n",
        "                if images_are_similar(image_bytes, logo_img):\n",
        "                    is_logo = True\n",
        "                    break\n",
        "            if not is_logo:\n",
        "                for j, saved_img in enumerate(saved_images):\n",
        "                    if images_are_similar(image_bytes, saved_img):\n",
        "                        is_logo = True\n",
        "                        try:\n",
        "                            os.remove(saved_paths[j])\n",
        "                        except:\n",
        "                            pass\n",
        "                        saved_images.pop(j)\n",
        "                        saved_paths.pop(j)\n",
        "                        break\n",
        "\n",
        "            if not is_logo:\n",
        "                saved_images.append(image_bytes)\n",
        "                img_path = os.path.join(output_dir, f\"{os.path.basename(pdf_path).replace('.pdf','')}_page{page_num+1}_img{i}.{image_ext}\")\n",
        "                saved_paths.append(img_path)\n",
        "                with open(img_path, \"wb\") as f:\n",
        "                    f.write(image_bytes)\n",
        "                print(f\"[✓] Saved: {img_path}\")\n",
        "            else:\n",
        "                skipped_logos.append(image_bytes)\n",
        "                print(f\"Skipped logo-like image on page {page_num+1}\")\n",
        "\n",
        "# --- STEP 3: Walk All PDFs ---\n",
        "def extract_from_all_pdfs(root_dir, output_base_dir):\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        for file in filenames:\n",
        "            if file.endswith(\".pdf\"):\n",
        "                pdf_path = os.path.join(dirpath, file)\n",
        "                rel_path = os.path.relpath(dirpath, root_dir)\n",
        "                output_dir = os.path.join(output_base_dir, rel_path)\n",
        "                extract_unique_images_from_pdf(pdf_path, output_dir)\n",
        "\n",
        "# --- Run the Whole Pipeline ---\n",
        "def process_all_pptx_and_pdfs(root_dir, output_image_dir):\n",
        "    convert_all_pptx_to_pdf(root_dir)\n",
        "    extract_from_all_pdfs(root_dir, output_image_dir)\n",
        "\n",
        "# Usage\n",
        "process_all_pptx_and_pdfs(\"/content/LLM_DATASET/LLM_DATASET\", \"image_stored\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTMZu7l3CFOk",
        "outputId": "7035099d-d15d-4dab-c28e-accca7210179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/binary_tree_traversal/Class5_Unit3_BST_Traversal.pptx -> /content/LLM_DATASET/LLM_DATASET/binary_tree_traversal/Class5_Unit3_BST_Traversal.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/BST/Class2_Unit3_Tree_BST_DynamicInsert.pptx -> /content/LLM_DATASET/LLM_DATASET/BST/Class2_Unit3_Tree_BST_DynamicInsert.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/BST/Class4_Unit3_Trees_BST_ArrayInsert.pptx -> /content/LLM_DATASET/LLM_DATASET/BST/Class4_Unit3_Trees_BST_ArrayInsert.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/BST/Class3_Unit3_Trees_BSTDeletion.pptx -> /content/LLM_DATASET/LLM_DATASET/BST/Class3_Unit3_Trees_BSTDeletion.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/Heap/Class8_Unit3_Trees_Heap.pptx -> /content/LLM_DATASET/LLM_DATASET/Heap/Class8_Unit3_Trees_Heap.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/Tree_traversal/class9_Unit3_Trees_naryTraversal.pptx -> /content/LLM_DATASET/LLM_DATASET/Tree_traversal/class9_Unit3_Trees_naryTraversal.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/TBT/Class6_Unit3_Trees_ThreadBST.pptx -> /content/LLM_DATASET/LLM_DATASET/TBT/Class6_Unit3_Trees_ThreadBST.pdf\n",
            "[✓] Converted: /content/LLM_DATASET/LLM_DATASET/expn_tree/Class7_Unit3_Trees_ExprTree.pptx -> /content/LLM_DATASET/LLM_DATASET/expn_tree/Class7_Unit3_Trees_ExprTree.pdf\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page1_img0.png\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page3_img0.jpeg\n",
            "Skipped logo-like image on page 4\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page4_img1.png\n",
            "Skipped logo-like image on page 5\n",
            "Skipped logo-like image on page 6\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page6_img1.jpeg\n",
            "Skipped logo-like image on page 7\n",
            "Skipped logo-like image on page 8\n",
            "Skipped logo-like image on page 9\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page9_img1.jpeg\n",
            "Skipped logo-like image on page 10\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page10_img1.jpeg\n",
            "Skipped logo-like image on page 11\n",
            "Skipped logo-like image on page 12\n",
            "Skipped logo-like image on page 13\n",
            "Skipped logo-like image on page 14\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page14_img1.jpeg\n",
            "Skipped logo-like image on page 15\n",
            "Skipped logo-like image on page 16\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page16_img1.jpeg\n",
            "Skipped logo-like image on page 17\n",
            "Skipped logo-like image on page 18\n",
            "Skipped logo-like image on page 19\n",
            "Skipped logo-like image on page 20\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page20_img1.png\n",
            "Skipped logo-like image on page 21\n",
            "Skipped logo-like image on page 22\n",
            "Skipped logo-like image on page 23\n",
            "Skipped logo-like image on page 24\n",
            "Skipped logo-like image on page 25\n",
            "Skipped logo-like image on page 26\n",
            "Skipped logo-like image on page 27\n",
            "Skipped logo-like image on page 28\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page28_img1.png\n",
            "Skipped logo-like image on page 29\n",
            "Skipped logo-like image on page 30\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page30_img1.png\n",
            "Skipped logo-like image on page 31\n",
            "Skipped logo-like image on page 32\n",
            "Skipped logo-like image on page 33\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page33_img1.png\n",
            "Skipped logo-like image on page 34\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page34_img1.png\n",
            "Skipped logo-like image on page 35\n",
            "Skipped logo-like image on page 36\n",
            "Skipped logo-like image on page 37\n",
            "Skipped logo-like image on page 38\n",
            "Skipped logo-like image on page 39\n",
            "Skipped logo-like image on page 40\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page40_img1.png\n",
            "Skipped logo-like image on page 41\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page41_img1.png\n",
            "Skipped logo-like image on page 42\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page42_img1.png\n",
            "Skipped logo-like image on page 43\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page43_img1.png\n",
            "Skipped logo-like image on page 44\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page44_img1.jpeg\n",
            "Skipped logo-like image on page 45\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page45_img1.png\n",
            "Skipped logo-like image on page 46\n",
            "Skipped logo-like image on page 47\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page47_img1.jpeg\n",
            "Skipped logo-like image on page 48\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page48_img1.png\n",
            "Skipped logo-like image on page 49\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page49_img1.png\n",
            "Skipped logo-like image on page 50\n",
            "Skipped logo-like image on page 50\n",
            "Skipped logo-like image on page 51\n",
            "Skipped logo-like image on page 51\n",
            "Skipped logo-like image on page 52\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page52_img1.png\n",
            "Skipped logo-like image on page 53\n",
            "Skipped logo-like image on page 54\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page54_img1.png\n",
            "Skipped logo-like image on page 55\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page55_img1.png\n",
            "Skipped logo-like image on page 56\n",
            "Skipped logo-like image on page 56\n",
            "Skipped logo-like image on page 57\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page57_img1.png\n",
            "Skipped logo-like image on page 58\n",
            "Skipped logo-like image on page 58\n",
            "Skipped logo-like image on page 59\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page59_img1.png\n",
            "Skipped logo-like image on page 60\n",
            "Skipped logo-like image on page 61\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page61_img1.png\n",
            "Skipped logo-like image on page 62\n",
            "Skipped logo-like image on page 63\n",
            "Skipped logo-like image on page 64\n",
            "Skipped logo-like image on page 65\n",
            "Skipped logo-like image on page 66\n",
            "Skipped logo-like image on page 67\n",
            "Skipped logo-like image on page 68\n",
            "Skipped logo-like image on page 69\n",
            "Skipped logo-like image on page 70\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page70_img1.png\n",
            "Skipped logo-like image on page 71\n",
            "Skipped logo-like image on page 72\n",
            "Skipped logo-like image on page 73\n",
            "Skipped logo-like image on page 74\n",
            "[✓] Saved: image_stored/stable_diffusion/Stable Diffusion_page75_img0.png\n",
            "[✓] Saved: image_stored/Multimodal/MultiModal LLMs_page1_img0.jpeg\n",
            "[✓] Saved: image_stored/Multimodal/MultiModal LLMs_page2_img0.jpeg\n",
            "Skipped logo-like image on page 3\n",
            "Skipped logo-like image on page 4\n",
            "Skipped logo-like image on page 5\n",
            "Skipped logo-like image on page 6\n",
            "[✓] Saved: image_stored/Multimodal/MultiModal LLMs_page6_img1.jpeg\n",
            "Skipped logo-like image on page 7\n",
            "Skipped logo-like image on page 8\n",
            "Skipped logo-like image on page 9\n",
            "[✓] Saved: image_stored/Multimodal/MultiModal LLMs_page9_img1.jpeg\n",
            "Skipped logo-like image on page 10\n",
            "[✓] Saved: image_stored/Multimodal/MultiModal LLMs_page10_img1.jpeg\n",
            "Skipped logo-like image on page 11\n",
            "Skipped logo-like image on page 12\n",
            "[✓] Saved: image_stored/Multimodal/MultiModal LLMs_page12_img1.jpeg\n",
            "Skipped logo-like image on page 13\n",
            "Skipped logo-like image on page 14\n",
            "Skipped logo-like image on page 15\n",
            "Skipped logo-like image on page 16\n",
            "Skipped logo-like image on page 17\n",
            "Skipped logo-like image on page 18\n",
            "Skipped logo-like image on page 19\n",
            "Skipped logo-like image on page 20\n",
            "Skipped logo-like image on page 21\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page1_img0.png\n",
            "Skipped logo-like image on page 2\n",
            "Skipped logo-like image on page 3\n",
            "Skipped logo-like image on page 4\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page4_img1.png\n",
            "Skipped logo-like image on page 5\n",
            "Skipped logo-like image on page 6\n",
            "Skipped logo-like image on page 7\n",
            "Skipped logo-like image on page 8\n",
            "Skipped logo-like image on page 9\n",
            "Skipped logo-like image on page 10\n",
            "Skipped logo-like image on page 11\n",
            "Skipped logo-like image on page 12\n",
            "Skipped logo-like image on page 13\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page13_img1.png\n",
            "Skipped logo-like image on page 14\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page14_img1.png\n",
            "Skipped logo-like image on page 15\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page15_img1.png\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page15_img2.png\n",
            "Skipped logo-like image on page 16\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page16_img1.png\n",
            "Skipped logo-like image on page 17\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page17_img1.png\n",
            "Skipped logo-like image on page 18\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page18_img1.png\n",
            "[✓] Saved: image_stored/Multimodal/MAMBA_page18_img2.png\n",
            "Skipped logo-like image on page 19\n",
            "Skipped logo-like image on page 20\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page1_img0.png\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page2_img0.png\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page2_img1.png\n",
            "Skipped logo-like image on page 3\n",
            "Skipped logo-like image on page 4\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page4_img1.png\n",
            "Skipped logo-like image on page 5\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page5_img1.png\n",
            "Skipped logo-like image on page 6\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page6_img1.png\n",
            "Skipped logo-like image on page 7\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page7_img1.png\n",
            "Skipped logo-like image on page 8\n",
            "Skipped logo-like image on page 8\n",
            "Skipped logo-like image on page 9\n",
            "Skipped logo-like image on page 10\n",
            "Skipped logo-like image on page 11\n",
            "Skipped logo-like image on page 12\n",
            "Skipped logo-like image on page 13\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page13_img1.png\n",
            "Skipped logo-like image on page 14\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page14_img1.png\n",
            "Skipped logo-like image on page 15\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page15_img1.png\n",
            "Skipped logo-like image on page 16\n",
            "Skipped logo-like image on page 17\n",
            "Skipped logo-like image on page 18\n",
            "Skipped logo-like image on page 19\n",
            "Skipped logo-like image on page 20\n",
            "[✓] Saved: image_stored/Lora&Qlora/Finetuning_page20_img1.png\n",
            "Skipped logo-like image on page 21\n",
            "Skipped logo-like image on page 22\n",
            "Skipped logo-like image on page 23\n",
            "[✓] Saved: image_stored/agentic/AutoGen, CrewAI_page1_img0.png\n",
            "[✓] Saved: image_stored/agentic/AutoGen, CrewAI_page1_img1.png\n",
            "[✓] Saved: image_stored/agentic/AutoGen, CrewAI_page1_img2.png\n",
            "[✓] Saved: image_stored/agentic/AutoGen, CrewAI_page1_img3.png\n",
            "[✓] Saved: image_stored/agentic/AutoGen, CrewAI_page2_img0.png\n",
            "Skipped logo-like image on page 3\n",
            "Skipped logo-like image on page 4\n",
            "Skipped logo-like image on page 5\n",
            "Skipped logo-like image on page 6\n",
            "Skipped logo-like image on page 7\n",
            "Skipped logo-like image on page 8\n",
            "Skipped logo-like image on page 9\n",
            "Skipped logo-like image on page 10\n",
            "[✓] Saved: image_stored/agentic/AutoGen, CrewAI_page11_img0.png\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page1_img0.png\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page2_img0.png\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page2_img1.png\n",
            "Skipped logo-like image on page 3\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page3_img1.png\n",
            "Skipped logo-like image on page 4\n",
            "Skipped logo-like image on page 5\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page5_img1.png\n",
            "Skipped logo-like image on page 6\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page6_img1.png\n",
            "Skipped logo-like image on page 7\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page7_img1.png\n",
            "Skipped logo-like image on page 8\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page8_img1.png\n",
            "Skipped logo-like image on page 9\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page9_img1.png\n",
            "Skipped logo-like image on page 10\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page10_img1.png\n",
            "Skipped logo-like image on page 11\n",
            "Skipped logo-like image on page 12\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page12_img1.png\n",
            "Skipped logo-like image on page 13\n",
            "[✓] Saved: image_stored/agentic/Agentic Workflow_page13_img1.png\n",
            "Skipped logo-like image on page 14\n",
            "Skipped logo-like image on page 15\n",
            "Skipped logo-like image on page 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# image captioning"
      ],
      "metadata": {
        "id": "w3X-GE0ZQsdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markdown2 pdfkit\n",
        "!sudo apt install wkhtmltopdf  # or brew install wkhtmltopdf (macOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iBSEAGZoom-",
        "outputId": "1520e27c-d2ab-4d0b-9a56-51531cc6d43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting markdown2\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pdfkit\n",
            "  Downloading pdfkit-1.0.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Downloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: pdfkit, markdown2\n",
            "Successfully installed markdown2-2.5.3 pdfkit-1.0.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n",
            "  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n",
            "  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libudev1 libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n",
            "  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n",
            "  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wpasupplicant\n",
            "Suggested packages:\n",
            "  avahi-autoipd gnome-shell | notification-daemon avahi-autoipd | zeroconf\n",
            "  qt5-image-formats-plugins qtwayland5 qt5-qmltooling-plugins comgt wvdial\n",
            "  wpagui libengine-pkcs11-openssl\n",
            "The following NEW packages will be installed:\n",
            "  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n",
            "  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n",
            "  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n",
            "  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n",
            "  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n",
            "  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n",
            "  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n",
            "  libsoup2.4-common libwacom-bin libwacom-common libwacom9 libwoff1\n",
            "  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n",
            "  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n",
            "  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wkhtmltopdf\n",
            "  wpasupplicant\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 67 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 35.5 MB of archives.\n",
            "After this operation, 141 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-core7 amd64 0.8-5ubuntu5.2 [90.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdaemon0 amd64 0.14-7.1ubuntu3 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 avahi-daemon amd64 0.8-5ubuntu5.2 [69.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.15 [76.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5positioning5 amd64 5.15.3+dfsg-3 [223 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qml5 amd64 5.15.3+dfsg-1 [1,472 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlmodels5 amd64 5.15.3+dfsg-1 [205 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quick5 amd64 5.15.3+dfsg-1 [1,748 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5sensors5 amd64 5.15.3-1 [123 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webchannel5 amd64 5.15.3-1 [62.9 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webkit5 amd64 5.212.0~alpha4-15ubuntu1 [12.8 MB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.15 [1,557 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmm-glib0 amd64 1.20.0-1~ubuntu22.04.4 [262 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.2 [4,192 B]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.2 [287 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 geoclue-2.0 amd64 2.5.7-3ubuntu3 [111 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 iio-sensor-proxy amd64 3.3-0ubuntu6 [34.4 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-glib4 amd64 1.28.0-1~ubuntu20.04.2 [192 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-proxy amd64 1.28.0-1~ubuntu20.04.2 [6,160 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnss-mdns amd64 0.15.1-1ubuntu1 [27.0 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-glib5 amd64 1.32.0-1ubuntu0.22.04.1 [772 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-proxy amd64 1.32.0-1ubuntu0.22.04.1 [6,072 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 modemmanager amd64 1.20.0-1~ubuntu22.04.4 [1,094 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 wpasupplicant amd64 2:2.10-6ubuntu2.2 [1,482 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch-data all 20191128-4 [33.2 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch amd64 2.6.1-3ubuntu2 [46.0 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 wkhtmltopdf amd64 0.12.6-2 [173 kB]\n",
            "Fetched 35.5 MB in 3s (11.9 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 68.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libavahi-core7:amd64.\n",
            "(Reading database ... 126332 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libavahi-core7_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libdaemon0:amd64.\n",
            "Preparing to unpack .../1-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\n",
            "Unpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Selecting previously unselected package avahi-daemon.\n",
            "Preparing to unpack .../2-avahi-daemon_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "Preparing to unpack .../3-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../4-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../5-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Preparing to unpack .../6-libudev1_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.15) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "(Reading database ... 126401 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../01-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../02-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../03-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../04-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../05-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../06-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../07-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../08-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../09-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../10-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../11-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../12-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../13-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../14-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../15-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../16-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../17-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../18-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../19-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../20-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libqt5positioning5:amd64.\n",
            "Preparing to unpack .../21-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\n",
            "Unpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Selecting previously unselected package libqt5printsupport5:amd64.\n",
            "Preparing to unpack .../22-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5qml5:amd64.\n",
            "Preparing to unpack .../23-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5qmlmodels5:amd64.\n",
            "Preparing to unpack .../24-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5quick5:amd64.\n",
            "Preparing to unpack .../25-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\n",
            "Unpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Selecting previously unselected package libqt5sensors5:amd64.\n",
            "Preparing to unpack .../26-libqt5sensors5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libqt5webchannel5:amd64.\n",
            "Preparing to unpack .../27-libqt5webchannel5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package libqt5webkit5:amd64.\n",
            "Preparing to unpack .../29-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\n",
            "Unpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Selecting previously unselected package udev.\n",
            "Preparing to unpack .../30-udev_249.11-0ubuntu3.15_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.15) ...\n",
            "Selecting previously unselected package libavahi-glib1:amd64.\n",
            "Preparing to unpack .../31-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...\n",
            "Unpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../32-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../33-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libmm-glib0:amd64.\n",
            "Preparing to unpack .../34-libmm-glib0_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../35-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../36-libproxy1v5_0.4.17-2_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../37-glib-networking-common_2.72.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../38-glib-networking-services_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.72.0-1) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../39-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../40-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../41-glib-networking_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.72.0-1) ...\n",
            "Selecting previously unselected package libsoup2.4-common.\n",
            "Preparing to unpack .../42-libsoup2.4-common_2.74.2-3ubuntu0.2_all.deb ...\n",
            "Unpacking libsoup2.4-common (2.74.2-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../43-libsoup2.4-1_2.74.2-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.2) ...\n",
            "Selecting previously unselected package geoclue-2.0.\n",
            "Preparing to unpack .../44-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\n",
            "Unpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Selecting previously unselected package iio-sensor-proxy.\n",
            "Preparing to unpack .../45-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\n",
            "Unpacking iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Selecting previously unselected package libmbim-glib4:amd64.\n",
            "Preparing to unpack .../46-libmbim-glib4_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libmbim-proxy.\n",
            "Preparing to unpack .../47-libmbim-proxy_1.28.0-1~ubuntu20.04.2_amd64.deb ...\n",
            "Unpacking libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Selecting previously unselected package libnl-genl-3-200:amd64.\n",
            "Preparing to unpack .../48-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\n",
            "Unpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Selecting previously unselected package libnss-mdns:amd64.\n",
            "Preparing to unpack .../49-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\n",
            "Unpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "Selecting previously unselected package libqmi-glib5:amd64.\n",
            "Preparing to unpack .../50-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libqmi-proxy.\n",
            "Preparing to unpack .../51-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../52-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package modemmanager.\n",
            "Preparing to unpack .../53-modemmanager_1.20.0-1~ubuntu22.04.4_amd64.deb ...\n",
            "Unpacking modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../54-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../55-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../56-systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Selecting previously unselected package wpasupplicant.\n",
            "Preparing to unpack .../57-wpasupplicant_2%3a2.10-6ubuntu2.2_amd64.deb ...\n",
            "Unpacking wpasupplicant (2:2.10-6ubuntu2.2) ...\n",
            "Selecting previously unselected package usb-modeswitch-data.\n",
            "Preparing to unpack .../58-usb-modeswitch-data_20191128-4_all.deb ...\n",
            "Unpacking usb-modeswitch-data (20191128-4) ...\n",
            "Selecting previously unselected package usb-modeswitch.\n",
            "Preparing to unpack .../59-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Selecting previously unselected package wkhtmltopdf.\n",
            "Preparing to unpack .../60-wkhtmltopdf_0.12.6-2_amd64.deb ...\n",
            "Unpacking wkhtmltopdf (0.12.6-2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up usb-modeswitch-data (20191128-4) ...\n",
            "Setting up udev (249.11-0ubuntu3.15) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libsoup2.4-common (2.74.2-3ubuntu0.2) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Setting up usb-modeswitch (2.6.1-3ubuntu2) ...\n",
            "Setting up glib-networking-common (2.72.0-1) ...\n",
            "Setting up libqt5sensors5:amd64 (5.15.3-1) ...\n",
            "Setting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\n",
            "Setting up libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\n",
            "Setting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\n",
            "First installation detected...\n",
            "Checking NSS setup...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up glib-networking-services (2.72.0-1) ...\n",
            "Setting up iio-sensor-proxy (3.3-0ubuntu6) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\n",
            "Setting up libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up wpasupplicant (2:2.10-6ubuntu2.2) ...\n",
            "Created symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service → /lib/systemd/system/wpa_supplicant.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service → /lib/systemd/system/wpa_supplicant.service.\n",
            "Setting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5webchannel5:amd64 (5.15.3-1) ...\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up avahi-daemon (0.8-5ubuntu5.2) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of force-reload.\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service → /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service → /lib/systemd/system/avahi-daemon.service.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket → /lib/systemd/system/avahi-daemon.socket.\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\n",
            "Setting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\n",
            "Setting up modemmanager (1.20.0-1~ubuntu22.04.4) ...\n",
            "Created symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service → /lib/systemd/system/ModemManager.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service → /lib/systemd/system/ModemManager.service.\n",
            "Setting up wkhtmltopdf (0.12.6-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.4) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Setting up glib-networking:amd64 (2.72.0-1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.2) ...\n",
            "Setting up geoclue-2.0 (2.5.7-3ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "# Load BLIP captioning model\n",
        "caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "caption_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = caption_processor(image, return_tensors=\"pt\")\n",
        "    out = caption_model.generate(**inputs)\n",
        "    return caption_processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# Gather and caption all images\n",
        "def get_image_captions(image_root):\n",
        "    image_captions = []\n",
        "    for img_path in sorted(Path(image_root).rglob(\"*.png\")):\n",
        "        try:\n",
        "            caption = generate_caption(img_path)\n",
        "            image_captions.append((img_path, caption))\n",
        "        except:\n",
        "            print(f\"Failed to caption: {img_path}\")\n",
        "    return image_captions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414,
          "referenced_widgets": [
            "ee1111b704dc46fb9144c50a90f4e4b6",
            "b7e0b2183ef346349d082e7b0792a5dd",
            "f22f092215334550a7e45ff2da215a52",
            "927982107008431eb96ed142f29a80b2",
            "7bd7ab5768cd40009311efa0fcc1c6da",
            "775248ee50d545d390a1ad17c1e06a8d",
            "c663e7c497584bcf9739f4e7ca631b83",
            "353f46a032d14400852f6cdf01f83b4a",
            "961f012ba95d4b9f9da0f556439a2295",
            "807ec3f417fe4a6a81019bbad5145267",
            "cbce81699efd4e15978216b28d077c93",
            "9102fba9b2724a0a9b8d72bb3390de39",
            "1646a8bd35484616a560a9a40e69a53a",
            "8b5b407386ec4342b9c5c0a1d150df51",
            "2d56f20479e04bdd801bba03a88ba0c5",
            "1b31dca0f9574ed194ce879e3755d657",
            "b72d42a1b75544e1b5e978d4f82c3603",
            "93d4f9177d2648ed951a5e6626050d21",
            "75c64cd0b3664c48a35174e1011e08d4",
            "d23a2bd4aebe498eb8a172ab949c45da",
            "e0ab41453d04428893cecb27d247c388",
            "ef1e4f913cdf4facaa2d01d6fce482b9",
            "7014c22ba3ee46168dedbda0ce0e9d33",
            "af478b4b46824780b56ed956bd60e009",
            "27dd17e0e6f24167a0885102f4d30f45",
            "52f069ba8b9741fe8f88af2ab05f26a1",
            "1651a88f3b25430ba8cb91be61d7f9f4",
            "562abd7269f143a3b25a77a7422e471b",
            "e22be12f6de4421e82b662d1180c6603",
            "5bda5fdb740542cdb268af98bd1553a5",
            "3ec71b11310a414da10014c15c9b00da",
            "4a68a9caef56497abad5aedd374f2a24",
            "697a86ccca5049cd82239abad39de273",
            "f8b82438cec24a21bfa6881daf274421",
            "8145243418de4daf99d3bc1f73788c19",
            "b5da93dd3b8f41beb56682d7b5e01ffa",
            "240a30befe3c414ca4b0cec82ce61be6",
            "3abe18364427405599db7f5885bf862b",
            "0d83a1b942af40c982802b3e1248c6c9",
            "b1925eb5a68d40ddb302bf76bb1f5c5b",
            "08153b798d1348768ae9dff57cf9f7a8",
            "70a7c01173e24a0698b77e13e1e692ed",
            "008ecade0bed4ffbb84ebf5d42babda7",
            "b5c0cc419031460593bafbd48850dc2f",
            "efbc8db23d364ef1bc2d9d0b509b942c",
            "7c3d5a7069614d349957c8e6918b2d5a",
            "f48b549721344828939ab17ff202287d",
            "759b4035afa544c2afbee2dbe8597304",
            "d907d491d0634b24ac7ead569c9b8651",
            "142d6c0480f94d3c93f342230f1c90c5",
            "7e6fdcf4c7fd4488a801dd87806f68d1",
            "6b3a5f71c1a14386915e331d9591ea60",
            "767538b549224a8887dc3a970faab138",
            "07c6df7555d84e01aeb444cfe892d08f",
            "9b306a9f01ca4096b69d6f33dea0dd67",
            "24d346858ae14a73b67ebd3e8ba5d9df",
            "b53f71b744304ecca2618b1f432579f6",
            "4eb1f87ba2794ce4ba9a79e298b97680",
            "13f0a9ffeac1470e89afdee45887e9e8",
            "7554c3646e43495881cfc37e7c049578",
            "8df9b94eb1a94e9195150d0b3930726a",
            "8670332b636045fba2c2dbe362dcc8d7",
            "aed8eaa2a0e34ceea580d00070a355ac",
            "052bbaa39f3b47fab992287781905da3",
            "be771dc5d4074c3badd804502eb6ffe9",
            "421f9a3a50574645b24c5e1f4cb3e11d",
            "b88e7af004984b8cadfecb633e5f7509",
            "1cf8e1f6f8854d60bec226cb7a4005a6",
            "11dbd3945ec84e6bbd0a906f0c99281d",
            "744b0bb46bd9494f970195a7fb089acf",
            "81c54f8a845a48e9951094583bb3db9a",
            "e47fe4bbcd6a419ebc27609b9b084f1e",
            "418965b5b3704624b1ed47564df80684",
            "761bd17d992049f288bbeb9173583c56",
            "5ecd9f90102148d48037913147436742",
            "b1e80a38a42b4feb88bb6f3aae69bb59",
            "f6ba21e62c2e42e48474097be5aa76ef",
            "0c3564b6b6a143ed8d5b00926883eb51",
            "eb6f0eff78304a1fa0b5c9a7baf3698a",
            "f4f53f3bebe34003ad50bf8f2a2ff920",
            "9a64990bae4c4e1f939cc652a5d739ec",
            "8a7a29da1f644db09e432ed8a156c34d",
            "5d4fafb27cdd4c629965300ac0f1dc81",
            "b8fc74c21f594bfa92b34478755abb01",
            "08312d49a4db46a899a5e75e8884b650",
            "51e7a89b2bfa4874866f45b3a91aadfa",
            "d8613bed9f6843bb94c1a060e1984d01",
            "570a64d878054317b8b1dbe5dea0d3f0"
          ]
        },
        "id": "u6f9TVO2LjQ2",
        "outputId": "c95233be-0e9d-47d1-d89b-7f7f7275e36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee1111b704dc46fb9144c50a90f4e4b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9102fba9b2724a0a9b8d72bb3390de39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7014c22ba3ee46168dedbda0ce0e9d33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8b82438cec24a21bfa6881daf274421"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efbc8db23d364ef1bc2d9d0b509b942c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24d346858ae14a73b67ebd3e8ba5d9df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b88e7af004984b8cadfecb633e5f7509"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c3564b6b6a143ed8d5b00926883eb51"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# integrating image to text notes"
      ],
      "metadata": {
        "id": "3tDLXtY6RHAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def match_captions_to_notes(captions, notes_text):\n",
        "    paragraphs = [p.strip() for p in notes_text.split('\\n\\n') if p.strip()]\n",
        "    para_embeddings = model.encode(paragraphs, convert_to_tensor=True)\n",
        "\n",
        "    matches = []\n",
        "    for path, caption in captions:\n",
        "        cap_embedding = model.encode(caption, convert_to_tensor=True)\n",
        "        similarity = util.cos_sim(cap_embedding, para_embeddings)[0]\n",
        "        best_idx = similarity.argmax().item()\n",
        "        matches.append((best_idx, path, caption))\n",
        "    return matches, paragraphs\n",
        "def inject_images(paragraphs, matches):\n",
        "    for idx, img_path, caption in sorted(matches, key=lambda x: x[0], reverse=True):\n",
        "        img_md = f\"\\n\\n![{caption}]({img_path.as_posix()})\"\n",
        "        paragraphs[idx] += img_md\n",
        "    return \"\\n\\n\".join(paragraphs)\n",
        "# Load your notes\n",
        "with open(\"/content/qlora_notes.md\", \"r\") as f:\n",
        "    notes_text = f.read()\n",
        "\n",
        "# Run pipeline\n",
        "captions = get_image_captions(\"/content/image_stored/Lora&Qlora\")\n",
        "matches, paragraphs = match_captions_to_notes(captions, notes_text)\n",
        "final_notes = inject_images(paragraphs, matches)\n",
        "\n",
        "# Save output\n",
        "with open(\"x.md\", \"w\") as f:\n",
        "    f.write(final_notes)\n"
      ],
      "metadata": {
        "id": "bVBzFIJ4oGek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# md to pdf"
      ],
      "metadata": {
        "id": "rAE3AWwLRUvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import markdown2\n",
        "import pdfkit\n",
        "import re\n",
        "import os\n",
        "\n",
        "def convert_md_to_pdf(md_path, output_pdf_path):\n",
        "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        md_content = f.read()\n",
        "    md_content = re.sub(r'!\\[(.*?)\\]\\((.*?)\\)', lambda m: f'![\\g<1>](file://{os.path.abspath(m.group(2))})', md_content)\n",
        "\n",
        "    html = markdown2.markdown(md_content)\n",
        "\n",
        "    pdfkit.from_string(html, output_pdf_path, options={'enable-local-file-access': None})\n",
        "\n",
        "    print(f\"PDF saved to: {output_pdf_path}\")\n",
        "\n",
        "convert_md_to_pdf(\"x.md\", \"qlora.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4kxQW7XrWX2",
        "outputId": "64db9c03-58c3-4c4c-cec5-2a8f81d95695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF saved to: qlora.pdf\n"
          ]
        }
      ]
    }
  ]
}