# -*- coding: utf-8 -*-
"""Transcribe-vid-ppt-pdf.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oi3xQ9XKfSHf-l04I-v6wyGgpuL51Uy3

**tree traveersal**

**Install all the dependencies**
"""

!pip install git+https://github.com/openai/whisper.git
!pip install python-pptx
!pip install ffmpeg-python
!pip install transformers
!apt install ffmpeg

"""**Convert the files from mkv to mp4 to support whisper api**

**Replace the video/audio/pdf/ppt files with your respective paths after uploading ( here its uploaded on colab )**
"""

import ffmpeg

def convert_mkv_to_mp4(input_path, output_path):
    ffmpeg.input(input_path).output(output_path).run(overwrite_output=True)
    print(f"Converted {input_path} to {output_path}")

video_mkv = "/content/9a_2020-09-16 09-46-13_TreeTravCon.mkv"
video_mp4 = "/content/converted_video.mp4"
convert_mkv_to_mp4(video_mkv, video_mp4)

"""**Extract the audio files **"""

def extract_audio(video_path, audio_path="/content/audio.wav"):
    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    print("Audio extracted:", audio_path)
    return audio_path

audio_file = extract_audio(video_mp4)

"""This code converts an MKV file to MP4, extracts its audio as a WAV file, and then transcribes the audio using OpenAI’s Whisper model. It ensures both video and audio formats are compatible for accurate transcription."""

import ffmpeg

def convert_and_extract_audio(mkv_path):
    mp4_path = mkv_path.replace(".mkv", ".mp4")
    audio_path = "/content/audio.wav"

    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)
    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)

    return mp4_path, audio_path

video_path = "/content/9a_2020-09-16 09-46-13_TreeTravCon.mkv"
converted_mp4, audio_file = convert_and_extract_audio(video_path)

import whisper

model = whisper.load_model("medium")  # or "large" for even better quality
result = model.transcribe(audio_file)
full_transcript = result["text"]

"""This code extracts titles, content, and speaker notes from each slide in a PowerPoint (.pptx) file. It organizes the extracted data into a structured list of dictionaries for further processing."""

from pptx import Presentation

def extract_ppt_content(ppt_path):
    prs = Presentation(ppt_path)
    slides = []

    for i, slide in enumerate(prs.slides):
        slide_dict = {'title': '', 'content': [], 'notes': ''}

        for shape in slide.shapes:
            if shape.has_text_frame:
                text = shape.text.strip()
                if shape == slide.shapes[0]:
                    slide_dict['title'] = text
                else:
                    slide_dict['content'].append(text)

        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            slide_dict['notes'] = slide.notes_slide.notes_text_frame.text.strip()

        slides.append(slide_dict)
    return slides

ppt_path = "/content/class9_Unit3_Trees_naryTraversal.pptx"
slide_data = extract_ppt_content(ppt_path)

!pip install fpdf

"""This code compiles the transcribed audio and extracted slide content into a well-formatted PDF titled Lecture Notes. It organizes each slide's title, content, and notes using the fpdf library and saves the final output.








"""

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1, align="L")
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

# Add full transcript
pdf.chapter_title("Full Transcript")
pdf.chapter_body(full_transcript)

# Add slide contents
for i, slide in enumerate(slide_data):
    pdf.chapter_title(f"Slide {i+1}: {slide['title']}")
    for point in slide['content']:
        pdf.chapter_body(f"- {point}")
    if slide['notes']:
        pdf.chapter_body(f"Notes: {slide['notes']}")
    pdf.ln()

output_pdf_path = "/content/Combined_Lecture_Notes.pdf"
pdf.output(output_pdf_path)
print(f"✅ PDF saved: {output_pdf_path}")

from google.colab import files
files.download(output_pdf_path)

"""**The same steps are repeated for each of the other subtopics **

**Agentic**
"""

!pip install git+https://github.com/openai/whisper.git
!pip install ffmpeg-python
!pip install PyMuPDF fpdf
!apt install ffmpeg -y

import ffmpeg

def extract_audio(video_path, audio_path="/content/audio_agentic.wav"):
    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    return audio_path

video_path = "/content/19853_shylaja.sharath_31_20250401121200417_Video_ENC.mp4"
audio_path = extract_audio(video_path)

import whisper

model = whisper.load_model("medium")  # Or "large" for better quality
result = model.transcribe(audio_file)
full_transcript = result["text"]

import fitz  # PyMuPDF

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    full_text = ""
    for page in doc:
        full_text += page.get_text()
    return full_text.strip()

slide_text_1 = extract_text_from_pdf("/content/Agentic Workflow.pdf")
slide_text_2 = extract_text_from_pdf("/content/AutoGen, CrewAI.pdf")

combined_slide_text = f"{slide_text_1}\n\n---\n\n{slide_text_2}"

# Step 5: Define clean_text and generate final PDF
from fpdf import FPDF

def clean_text(text):
    return (
        text.encode("ascii", "ignore")  # removes any non-ascii character
        .decode("ascii")
        .replace('\u2013', '-')         # en-dash
        .replace('\u2014', '-')         # em-dash
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Agentic Workflow - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.chapter_title("Video Transcript")
pdf.chapter_body(clean_text(full_transcript))

pdf.chapter_title("Slide Content - Agentic Workflow & CrewAI")
pdf.chapter_body(clean_text(combined_slide_text))

output_pdf_path = "/content/Agentic_Complete_Lecture_Notes.pdf"
pdf.output(output_pdf_path)
print(f"✅ Full Lecture Notes PDF saved to: {output_pdf_path}")

# Step 6: Download the final output
from google.colab import files
files.download(output_pdf_path)

"""**BST**"""

!pip install python-pptx fpdf

from pptx import Presentation

def extract_pptx_text(path):
    prs = Presentation(path)
    content = ""

    for i, slide in enumerate(prs.slides):
        slide_title = ""
        bullet_points = []
        notes = ""

        for shape in slide.shapes:
            if shape.has_text_frame:
                text = shape.text.strip()
                if shape == slide.shapes[0] and not slide_title:
                    slide_title = text
                else:
                    bullet_points.append(text)

        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            notes = slide.notes_slide.notes_text_frame.text.strip()

        content += f"\n\nSlide {i+1}: {slide_title}\n"
        for bullet in bullet_points:
            content += f"- {bullet}\n"
        if notes:
            content += f"Notes: {notes}\n"

    return content

# Paths to the 3 files
ppt1 = "/content/Class2_Unit3_Tree_BST_DynamicInsert.pptx"
ppt2 = "/content/Class3_Unit3_Trees_BSTDeletion.pptx"
ppt3 = "/content/Class4_Unit3_Trees_BST_ArrayInsert.pptx"

# Combine all content
combined_bst_text = (
    extract_pptx_text(ppt1)
    + "\n\n" + extract_pptx_text(ppt2)
    + "\n\n" + extract_pptx_text(ppt3)
)

def clean_text(text):
    return (
        text.encode("ascii", "ignore")
        .decode("ascii")
        .replace('\u2013', '-')
        .replace('\u2014', '-')
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Binary Search Tree (BST) - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()
pdf.chapter_title("Combined Slide Transcription - BST Lectures")
pdf.chapter_body(clean_text(combined_bst_text))

output_pdf_path = "/content/BST_Lecture_Notes.pdf"
pdf.output(output_pdf_path)
print(f"✅ PDF created: {output_pdf_path}")

from google.colab import files
files.download(output_pdf_path)

"""**TBT**"""

import ffmpeg

def convert_and_extract_audio(mkv_path, out_prefix):
    mp4_path = mkv_path.replace(".mkv", f"_{out_prefix}.mp4")
    audio_path = f"/content/audio_{out_prefix}.wav"

    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)
    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    return audio_path

# Convert and extract from both videos
audio1 = convert_and_extract_audio("/content/6a_2020-09-22 09-49-32_TBTCon.mkv", "part1")
audio2 = convert_and_extract_audio("/content/6b_2020-09-25 11-29-19_TBTCode 00_00_04-00_35_19~8.mkv", "part2")

import whisper

model = whisper.load_model("large")  # or "large" for even higher accuracy

transcript1 = model.transcribe(audio1)["text"]
transcript2 = model.transcribe(audio2)["text"]

full_video_transcript = transcript1 + "\n\n---\n\n" + transcript2

from pptx import Presentation

def extract_pptx_text(path):
    prs = Presentation(path)
    content = ""

    for i, slide in enumerate(prs.slides):
        slide_title = ""
        bullet_points = []
        notes = ""

        for shape in slide.shapes:
            if shape.has_text_frame:
                text = shape.text.strip()
                if shape == slide.shapes[0] and not slide_title:
                    slide_title = text
                else:
                    bullet_points.append(text)

        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            notes = slide.notes_slide.notes_text_frame.text.strip()

        content += f"\n\nSlide {i+1}: {slide_title}\n"
        for bullet in bullet_points:
            content += f"- {bullet}\n"
        if notes:
            content += f"Notes: {notes}\n"

    return content

ppt_path = "/content/Class6_Unit3_Trees_ThreadBST.pptx"
slide_text = extract_pptx_text(ppt_path)

def clean_text(text):
    return (
        text.encode("ascii", "ignore")
        .decode("ascii")
        .replace('\u2013', '-')
        .replace('\u2014', '-')
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Threaded Binary Tree (TBT) - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.chapter_title("Video Transcript (Part 1 + Part 2)")
pdf.chapter_body(clean_text(full_video_transcript))

pdf.chapter_title("Slide Content from PPT")
pdf.chapter_body(clean_text(slide_text))

output_pdf = "/content/TBT_Lecture_Notes.pdf"
pdf.output(output_pdf)
print(f"✅ Final TBT Lecture PDF saved: {output_pdf}")

from google.colab import files
files.download(output_pdf)

"""**heap**"""

import ffmpeg

def convert_and_extract_audio(mkv_path, out_prefix):
    mp4_path = mkv_path.replace(".mkv", f"_{out_prefix}.mp4")
    audio_path = f"/content/audio_{out_prefix}.wav"

    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)
    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    return audio_path

audio1 = convert_and_extract_audio("/content/8a_2020-09-24 13-07-04_HeapCon 00_00_01-00_42_12~1.mkv", "heap_part1")
audio2 = convert_and_extract_audio("/content/8b_2020-09-26 09-34-27_HeapCode 00_00_09-00_56_50.mkv", "heap_part2")

import whisper

model = whisper.load_model("medium")  # Or "large" for best results

transcript1 = model.transcribe(audio1)["text"]
transcript2 = model.transcribe(audio2)["text"]

heap_full_transcript = transcript1 + "\n\n---\n\n" + transcript2

from pptx import Presentation

def extract_pptx_text(path):
    prs = Presentation(path)
    content = ""

    for i, slide in enumerate(prs.slides):
        slide_title = ""
        bullet_points = []
        notes = ""

        for shape in slide.shapes:
            if shape.has_text_frame:
                text = shape.text.strip()
                if shape == slide.shapes[0] and not slide_title:
                    slide_title = text
                else:
                    bullet_points.append(text)

        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            notes = slide.notes_slide.notes_text_frame.text.strip()

        content += f"\n\nSlide {i+1}: {slide_title}\n"
        for bullet in bullet_points:
            content += f"- {bullet}\n"
        if notes:
            content += f"Notes: {notes}\n"

    return content

ppt_path = "/content/Class8_Unit3_Trees_Heap.pptx"
heap_slide_text = extract_pptx_text(ppt_path)

def clean_text(text):
    return (
        text.encode("ascii", "ignore")
        .decode("ascii")
        .replace('\u2013', '-')
        .replace('\u2014', '-')
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Heap - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.chapter_title("Video Transcript (Both Parts)")
pdf.chapter_body(clean_text(heap_full_transcript))

pdf.chapter_title("Slide Content - Heap PPT")
pdf.chapter_body(clean_text(heap_slide_text))

output_pdf_path = "/content/Heap_Lecture_Notes.pdf"
pdf.output(output_pdf_path)
print(f"✅ Final Heap Lecture PDF saved: {output_pdf_path}")

from google.colab import files
files.download(output_pdf_path)

"""**exp_tree**"""

import ffmpeg

def convert_and_extract_audio(mkv_path, out_prefix):
    mp4_path = mkv_path.replace(".mkv", f"_{out_prefix}.mp4")
    audio_path = f"/content/audio_{out_prefix}.wav"

    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)
    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    return audio_path

audio1 = convert_and_extract_audio("/content/7a_2020-09-24 09-28-52_ExprTreeCon.mkv", "expn1")
audio2 = convert_and_extract_audio("/content/7b_2020-09-25 12-12-37_ExprTReeCode 00_00_09-00_26_52.mkv", "expn2")

import whisper

model = whisper.load_model("large")
transcript1 = model.transcribe(audio1)["text"]
transcript2 = model.transcribe(audio2)["text"]

full_expn_transcript = transcript1 + "\n\n---\n\n" + transcript2

from pptx import Presentation

def extract_pptx_text(path):
    prs = Presentation(path)
    content = ""

    for i, slide in enumerate(prs.slides):
        slide_title = ""
        bullet_points = []
        notes = ""

        for shape in slide.shapes:
            if shape.has_text_frame:
                text = shape.text.strip()
                if shape == slide.shapes[0] and not slide_title:
                    slide_title = text
                else:
                    bullet_points.append(text)

        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            notes = slide.notes_slide.notes_text_frame.text.strip()

        content += f"\n\nSlide {i+1}: {slide_title}\n"
        for bullet in bullet_points:
            content += f"- {bullet}\n"
        if notes:
            content += f"Notes: {notes}\n"

    return content

expn_slide_text = extract_pptx_text("/content/Class7_Unit3_Trees_ExprTree.pptx")

def clean_text(text):
    return (
        text.encode("ascii", "ignore")
        .decode("ascii")
        .replace('\u2013', '-')
        .replace('\u2014', '-')
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Expression Tree - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.chapter_title("Video Transcript (Part 1 + Part 2)")
pdf.chapter_body(clean_text(full_expn_transcript))

pdf.chapter_title("Slide Content - Expression Tree PPT")
pdf.chapter_body(clean_text(expn_slide_text))

output_pdf = "/content/ExpressionTree_Lecture_Notes.pdf"
pdf.output(output_pdf)
print(f"✅ Final Expression Tree Lecture PDF saved: {output_pdf}")

from google.colab import files
files.download(output_pdf)

"""**Stable Diffusion**"""

import ffmpeg

def extract_audio(video_path, out_name):
    audio_path = f"/content/audio_{out_name}.wav"
    ffmpeg.input(video_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    return audio_path

audio1 = extract_audio("/content/19853_shylaja.sharath_31_20250327084200249_Video_ENC.mp4", "stable1")
audio2 = extract_audio("/content/19853_shylaja.sharath_31_20250327092700214_Video_ENC (1).mp4", "stable2")

import whisper

model = whisper.load_model("large")  # or "large"

transcript1 = model.transcribe(audio1)["text"]
transcript2 = model.transcribe(audio2)["text"]

full_stable_video_transcript = transcript1 + "\n\n---\n\n" + transcript2

import fitz  # PyMuPDF

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text.strip()

slide_text = extract_text_from_pdf("/content/Stable Diffusion.pdf")

def clean_text(text):
    return (
        text.encode("ascii", "ignore")
        .decode("ascii")
        .replace('\u2013', '-')
        .replace('\u2014', '-')
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "Stable Diffusion - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.chapter_title("Video Transcript (Both Videos)")
pdf.chapter_body(clean_text(full_stable_video_transcript))

pdf.chapter_title("Slide Content - Stable Diffusion PDF")
pdf.chapter_body(clean_text(slide_text))

output_pdf = "/content/StableDiffusion_Lecture_Notes.pdf"
pdf.output(output_pdf)
print(f"✅ Final Stable Diffusion Lecture PDF saved: {output_pdf}")

from google.colab import files
files.download(output_pdf)

"""**Binary Tree Traversal**"""

import ffmpeg

def convert_and_extract_audio(mkv_path, out_prefix):
    mp4_path = mkv_path.replace(".mkv", f"_{out_prefix}.mp4")
    audio_path = f"/content/audio_{out_prefix}.wav"

    ffmpeg.input(mkv_path).output(mp4_path).run(overwrite_output=True)
    ffmpeg.input(mp4_path).output(audio_path, ac=1, ar='16000').run(overwrite_output=True)
    return audio_path

audio_path = convert_and_extract_audio("/content/5a_2020-09-15 09-04-51_BinTraversal.mkv", "bst_traversal")

import whisper

model = whisper.load_model("medium")  # or "large"
transcript = model.transcribe(audio_path)["text"]

from pptx import Presentation

def extract_pptx_text(path):
    prs = Presentation(path)
    content = ""

    for i, slide in enumerate(prs.slides):
        slide_title = ""
        bullet_points = []
        notes = ""

        for shape in slide.shapes:
            if shape.has_text_frame:
                text = shape.text.strip()
                if shape == slide.shapes[0] and not slide_title:
                    slide_title = text
                else:
                    bullet_points.append(text)

        if slide.has_notes_slide and slide.notes_slide.notes_text_frame:
            notes = slide.notes_slide.notes_text_frame.text.strip()

        content += f"\n\nSlide {i+1}: {slide_title}\n"
        for bullet in bullet_points:
            content += f"- {bullet}\n"
        if notes:
            content += f"Notes: {notes}\n"

    return content

ppt_text = extract_pptx_text("/content/Class5_Unit3_BST_Traversal.pptx")

def clean_text(text):
    return (
        text.encode("ascii", "ignore")
        .decode("ascii")
        .replace('\u2013', '-')
        .replace('\u2014', '-')
        .replace('\u2018', "'")
        .replace('\u2019', "'")
        .replace('\u201c', '"')
        .replace('\u201d', '"')
    )

from fpdf import FPDF

class PDF(FPDF):
    def header(self):
        self.set_font("Arial", "B", 14)
        self.cell(0, 10, "BST Traversal - Lecture Notes", ln=1, align="C")

    def chapter_title(self, title):
        self.set_font("Arial", "B", 12)
        self.cell(0, 10, title, ln=1)
        self.ln(2)

    def chapter_body(self, body):
        self.set_font("Arial", "", 11)
        self.multi_cell(0, 8, body)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.chapter_title("Video Transcript")
pdf.chapter_body(clean_text(transcript))

pdf.chapter_title("Slide Content - BST Traversal PPT")
pdf.chapter_body(clean_text(ppt_text))

output_pdf_path = "/content/BST_Traversal_Lecture_Notes.pdf"
pdf.output(output_pdf_path)
print(f"✅ Final BST Traversal Lecture PDF saved: {output_pdf_path}")

from google.colab import files
files.download(output_pdf_path)

"""# text summarization"""

import os
import fitz
import requests

os.environ["GROQ_API_KEY"] = "my_key"
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

def extract_text_from_pdf(pdf_path):
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text

def generate_notes_with_groq(transcript_text):
    prompt = f"""
You are an educational assistant. Your task is to generate detailed, well-structured lecture notes
by combining the transcript and slides content below. Do NOT include any introduction, explanation, or instructions in your output.
Follow these rules:
1. Use headings and subheadings.
2. Highlight key concepts and definitions.
3. Summarize lengthy explanations concisely.
4. Maintain logical flow.
5. Add bullet points for clarity.
---Transcript---
{transcript_text}

Return only the structured notes.
"""

    response = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {GROQ_API_KEY}"},
        json={
            "model": "qwen-qwq-32b",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
        }
    )

    response_json = response.json()
    if "choices" not in response_json:
        print("Error response from Groq:", response_json)
        return "Groq API error: could not generate notes."

    return response_json["choices"][0]["message"]["content"]

transcript = extract_text_from_pdf("/content/ExpressionTree_Combined.pdf")
lecture_notes = generate_notes_with_groq(transcript)

with open("expressiontree_notes.md", "w") as f:
    f.write(lecture_notes)

print("Lecture notes generated and saved.")

"""# image extraction"""

import fitz  # PyMuPDF
import os
from PIL import Image
import io
import numpy as np
from skimage.metrics import structural_similarity as ssim
import shutil
import platform

# --- STEP 1: Convert PPTX to PDF ---
def convert_pptx_to_pdf_windows(input_path, output_path):
    import comtypes.client
    powerpoint = comtypes.client.CreateObject("PowerPoint.Application")
    powerpoint.Visible = 1
    deck = powerpoint.Presentations.Open(input_path)
    deck.SaveAs(output_path, 32)  # 32 = PDF
    deck.Close()
    powerpoint.Quit()

def convert_pptx_to_pdf_linux(input_path, output_path):
    os.system(f'unoconv -f pdf -o "{output_path}" "{input_path}"')

def convert_all_pptx_to_pdf(root_dir):
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if file.endswith(".pptx"):
                pptx_path = os.path.join(dirpath, file)
                pdf_name = file.replace(".pptx", ".pdf")
                pdf_path = os.path.join(dirpath, pdf_name)
                try:
                    if platform.system() == "Windows":
                        convert_pptx_to_pdf_windows(pptx_path, pdf_path)
                    else:
                        convert_pptx_to_pdf_linux(pptx_path, pdf_path)
                    print(f"[✓] Converted: {pptx_path} -> {pdf_path}")
                except Exception as e:
                    print(f"[✗] Failed to convert {pptx_path}: {e}")

# --- STEP 2: PDF Image Extraction ---
def images_are_similar(img1_bytes, img2_bytes, threshold=0.96):
    img1 = Image.open(io.BytesIO(img1_bytes)).convert("L")
    img2 = Image.open(io.BytesIO(img2_bytes)).convert("L")
    if img1.size != img2.size:
        return False
    score, _ = ssim(np.array(img1), np.array(img2), full=True)
    return score >= threshold

def extract_unique_images_from_pdf(pdf_path, output_dir):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    pdf = fitz.open(pdf_path)
    saved_images = []
    skipped_logos = []
    saved_paths = []

    for page_num in range(len(pdf)):
        page = pdf[page_num]
        images = page.get_images(full=True)
        for i, img in enumerate(images):
            xref = img[0]
            base_image = pdf.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            is_logo = False
            for logo_img in skipped_logos:
                if images_are_similar(image_bytes, logo_img):
                    is_logo = True
                    break
            if not is_logo:
                for j, saved_img in enumerate(saved_images):
                    if images_are_similar(image_bytes, saved_img):
                        is_logo = True
                        try:
                            os.remove(saved_paths[j])
                        except:
                            pass
                        saved_images.pop(j)
                        saved_paths.pop(j)
                        break

            if not is_logo:
                saved_images.append(image_bytes)
                img_path = os.path.join(output_dir, f"{os.path.basename(pdf_path).replace('.pdf','')}_page{page_num+1}_img{i}.{image_ext}")
                saved_paths.append(img_path)
                with open(img_path, "wb") as f:
                    f.write(image_bytes)
                print(f"[✓] Saved: {img_path}")
            else:
                skipped_logos.append(image_bytes)
                print(f"Skipped logo-like image on page {page_num+1}")

# --- STEP 3: Walk All PDFs ---
def extract_from_all_pdfs(root_dir, output_base_dir):
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if file.endswith(".pdf"):
                pdf_path = os.path.join(dirpath, file)
                rel_path = os.path.relpath(dirpath, root_dir)
                output_dir = os.path.join(output_base_dir, rel_path)
                extract_unique_images_from_pdf(pdf_path, output_dir)

# --- Run the Whole Pipeline ---
def process_all_pptx_and_pdfs(root_dir, output_image_dir):
    convert_all_pptx_to_pdf(root_dir)
    extract_from_all_pdfs(root_dir, output_image_dir)

# Usage
process_all_pptx_and_pdfs("/content/LLM_DATASET/LLM_DATASET", "image_stored")

"""# image captioning"""

!pip install markdown2 pdfkit
!sudo apt install wkhtmltopdf  # or brew install wkhtmltopdf (macOS)

from pathlib import Path
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

# Load BLIP captioning model
caption_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
caption_processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")

def generate_caption(image_path):
    image = Image.open(image_path).convert("RGB")
    inputs = caption_processor(image, return_tensors="pt")
    out = caption_model.generate(**inputs)
    return caption_processor.decode(out[0], skip_special_tokens=True)

# Gather and caption all images
def get_image_captions(image_root):
    image_captions = []
    for img_path in sorted(Path(image_root).rglob("*.png")):
        try:
            caption = generate_caption(img_path)
            image_captions.append((img_path, caption))
        except:
            print(f"Failed to caption: {img_path}")
    return image_captions

"""# integrating image to text notes"""

from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer("all-MiniLM-L6-v2")

def match_captions_to_notes(captions, notes_text):
    paragraphs = [p.strip() for p in notes_text.split('\n\n') if p.strip()]
    para_embeddings = model.encode(paragraphs, convert_to_tensor=True)

    matches = []
    for path, caption in captions:
        cap_embedding = model.encode(caption, convert_to_tensor=True)
        similarity = util.cos_sim(cap_embedding, para_embeddings)[0]
        best_idx = similarity.argmax().item()
        matches.append((best_idx, path, caption))
    return matches, paragraphs
def inject_images(paragraphs, matches):
    for idx, img_path, caption in sorted(matches, key=lambda x: x[0], reverse=True):
        img_md = f"\n\n![{caption}]({img_path.as_posix()})"
        paragraphs[idx] += img_md
    return "\n\n".join(paragraphs)
# Load your notes
with open("/content/qlora_notes.md", "r") as f:
    notes_text = f.read()

# Run pipeline
captions = get_image_captions("/content/image_stored/Lora&Qlora")
matches, paragraphs = match_captions_to_notes(captions, notes_text)
final_notes = inject_images(paragraphs, matches)

# Save output
with open("x.md", "w") as f:
    f.write(final_notes)

"""# md to pdf"""

import markdown2
import pdfkit
import re
import os

def convert_md_to_pdf(md_path, output_pdf_path):
    with open(md_path, "r", encoding="utf-8") as f:
        md_content = f.read()
    md_content = re.sub(r'!\[(.*?)\]\((.*?)\)', lambda m: f'![\g<1>](file://{os.path.abspath(m.group(2))})', md_content)

    html = markdown2.markdown(md_content)

    pdfkit.from_string(html, output_pdf_path, options={'enable-local-file-access': None})

    print(f"PDF saved to: {output_pdf_path}")

convert_md_to_pdf("x.md", "qlora.pdf")